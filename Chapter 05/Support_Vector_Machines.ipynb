{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 5: Support Vector Machines\n",
        "\n",
        "Support Vector Machines (SVM) merupakan salah satu algoritma pembelajaran mesin yang dikenal memiliki performa tinggi serta fleksibilitas yang luas. Algoritma ini tidak hanya digunakan untuk permasalahan klasifikasi, tetapi juga dapat diterapkan pada regresi dan pendeteksian anomali.\n",
        "\n",
        "Keunggulan utama SVM terletak pada kemampuannya membangun decision boundary dengan margin maksimum. Dengan margin yang lebar, model cenderung memiliki kemampuan generalisasi yang lebih baik ketika dihadapkan pada data baru yang belum pernah dilihat sebelumnya.\n",
        "\n",
        "Pada chapter ini, pembahasan difokuskan pada:\n",
        "- konsep large margin classification,\n",
        "- perbedaan antara hard margin dan soft margin,\n",
        "- SVM linear dan non-linear,\n",
        "- penggunaan kernel trick,\n",
        "- penerapan SVM untuk regresi,\n",
        "- serta gambaran konseptual dan matematis dari mekanisme kerja SVM.\n",
        "\n",
        "Pemahaman terhadap SVM menjadi sangat penting karena konsep margin dan kernel merupakan fondasi bagi banyak metode Machine Learning lanjutan.\n"
      ],
      "metadata": {
        "id": "ajGrKnHrPjNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Linear SVM Classification\n",
        "\n",
        "Inti dari algoritma SVM adalah prinsip large margin classification. Alih-alih hanya memisahkan kelas secara benar, SVM berusaha mencari decision boundary yang berada sejauh mungkin dari titik data terdekat dari masing-masing kelas.\n",
        "\n",
        "Decision boundary dengan margin yang besar umumnya lebih stabil dan memiliki tingkat generalisasi yang lebih baik. Titik-titik data yang berada tepat pada batas margin disebut sebagai support vectors.\n",
        "\n",
        "Menariknya, hanya support vectors inilah yang secara langsung menentukan posisi dan orientasi decision boundary. Titik data lain yang berada jauh dari margin tidak memengaruhi bentuk boundary.\n"
      ],
      "metadata": {
        "id": "uyyIwimCPmKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Sensitivity to Feature Scales\n",
        "\n",
        "SVM sangat peka terhadap perbedaan skala fitur. Apabila satu fitur memiliki rentang nilai yang jauh lebih besar dibandingkan fitur lainnya, maka decision boundary dapat menjadi tidak seimbang dan bias terhadap fitur tersebut.\n",
        "\n",
        "Oleh karena itu, proses feature scaling, seperti standardisasi menggunakan StandardScaler, hampir selalu menjadi langkah wajib sebelum melatih model SVM.\n"
      ],
      "metadata": {
        "id": "a9xyJ9eHPnnd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Soft Margin Classification\n",
        "\n",
        "Dalam kondisi ideal, seluruh data dapat dipisahkan secara sempurna menggunakan decision boundary linear (hard margin). Namun pada data dunia nyata, kondisi ini jarang terjadi karena:\n",
        "- data sering kali tidak sepenuhnya linearly separable,\n",
        "- adanya noise dan outlier.\n",
        "\n",
        "Untuk mengatasi permasalahan tersebut, SVM menerapkan konsep soft margin, yaitu mengizinkan sejumlah pelanggaran margin demi memperoleh model yang lebih robust.\n",
        "\n",
        "Trade-off antara margin yang lebar dan jumlah kesalahan dikendalikan oleh hyperparameter C.\n",
        "- Nilai C kecil membuat model lebih toleran terhadap kesalahan dan menghasilkan margin yang lebih lebar.\n",
        "- Nilai C besar memaksa model mengklasifikasikan data seakurat mungkin, tetapi meningkatkan risiko overfitting.\n"
      ],
      "metadata": {
        "id": "q-yWJt3qPovA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Linear SVM Classification with Scikit-Learn\n",
        "\n",
        "Pada bagian ini, dilakukan pelatihan Linear SVM untuk kasus binary classification menggunakan dataset Iris. Tujuan model adalah mengidentifikasi apakah sebuah bunga termasuk spesies Iris virginica atau bukan.\n",
        "\n",
        "Dataset difokuskan pada dua fitur, yaitu panjang dan lebar kelopak bunga, agar decision boundary dapat dianalisis secara lebih intuitif.\n"
      ],
      "metadata": {
        "id": "aWSSRSG-Pppj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxtlU9U_O0Sl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
        "y = (iris[\"target\"] == 2).astype(np.float64)  # Iris virginica\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_clf = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\")),\n",
        "])\n",
        "\n",
        "svm_clf.fit(X, y)\n"
      ],
      "metadata": {
        "id": "dHzvrx2iPtzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline di atas memastikan bahwa data mengalami proses standardisasi sebelum digunakan oleh model Linear SVM. Penggunaan loss function hinge sesuai dengan formulasi klasik SVM yang bertujuan memaksimalkan margin.\n"
      ],
      "metadata": {
        "id": "GO2lBUABPve1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Making Predictions\n",
        "\n",
        "Setelah model dilatih, model dapat digunakan untuk melakukan prediksi pada data baru. Output prediksi berupa label kelas, bukan probabilitas.\n"
      ],
      "metadata": {
        "id": "8tgQQB7zPxDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_clf.predict([[5.5, 1.7]])\n"
      ],
      "metadata": {
        "id": "BnKyG5TgPyFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berbeda dengan Logistic Regression, SVM tidak secara langsung menghasilkan probabilitas kelas. Output prediksi menunjukkan kelas hasil keputusan model.\n"
      ],
      "metadata": {
        "id": "HJSSYstVPzj2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Nonlinear SVM Classification\n",
        "\n",
        "Tidak semua dataset dapat dipisahkan menggunakan decision boundary linear. Pada kondisi tersebut, Linear SVM tidak mampu memberikan hasil yang memadai.\n",
        "\n",
        "Untuk mengatasi keterbatasan ini, SVM dapat diperluas menjadi model non-linear dengan cara memetakan data ke ruang berdimensi lebih tinggi, di mana data menjadi linearly separable.\n"
      ],
      "metadata": {
        "id": "ypw5KeUgP0yl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Polynomial Features\n",
        "\n",
        "Pendekatan sederhana untuk menangani non-linearitas adalah dengan menambahkan fitur polinomial. Dengan menambahkan kombinasi non-linear dari fitur asli, model linear dapat mempelajari boundary yang non-linear di ruang input.\n"
      ],
      "metadata": {
        "id": "MSpjXz3QP2F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "X, y = make_moons(n_samples=100, noise=0.15, random_state=42)\n"
      ],
      "metadata": {
        "id": "JJN055usP3Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "polynomial_svm_clf = Pipeline([\n",
        "    (\"poly_features\", PolynomialFeatures(degree=3)),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"linear_svc\", LinearSVC(C=10, loss=\"hinge\"))\n",
        "])\n",
        "\n",
        "polynomial_svm_clf.fit(X, y)\n"
      ],
      "metadata": {
        "id": "2HiphujfP41u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pendekatan ini efektif untuk menangani data non-linear, namun jumlah fitur dapat meningkat sangat cepat seiring bertambahnya derajat polinomial.\n"
      ],
      "metadata": {
        "id": "LN9wpqGCP6ty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. The Kernel Trick (Pengantar)\n",
        "\n",
        "Untuk menghindari eksplosinya jumlah fitur akibat penambahan fitur polinomial secara eksplisit, SVM memanfaatkan teknik yang dikenal sebagai kernel trick.\n",
        "\n",
        "Kernel trick memungkinkan perhitungan hubungan di ruang berdimensi tinggi tanpa perlu benar-benar melakukan transformasi eksplisit ke ruang tersebut, sehingga tetap efisien secara komputasi.\n"
      ],
      "metadata": {
        "id": "O5H1PwjcP8Qn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Polynomial Kernel\n",
        "\n",
        "Polynomial kernel memungkinkan SVM mempelajari decision boundary non-linear secara efisien melalui kernel trick. Kernel ini memiliki beberapa hyperparameter penting, seperti degree, coef0, dan C, yang memengaruhi kompleksitas model.\n"
      ],
      "metadata": {
        "id": "BMShjiozP9jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "poly_kernel_svm_clf = SVC(kernel=\"poly\", degree=3, coef0=1, C=5)\n",
        "poly_kernel_svm_clf.fit(X, y)\n"
      ],
      "metadata": {
        "id": "7sAZ904lP-gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Gaussian Radial Basis Function (RBF) Kernel\n",
        "\n",
        "RBF kernel merupakan salah satu kernel paling populer dalam SVM. Kernel ini memungkinkan pembentukan decision boundary yang sangat fleksibel dan kompleks dengan mengukur tingkat kemiripan antar instance data.\n"
      ],
      "metadata": {
        "id": "-3sKL_BZP_kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rbf_kernel_svm_clf = SVC(kernel=\"rbf\", gamma=0.5, C=1)\n",
        "rbf_kernel_svm_clf.fit(X, y)\n"
      ],
      "metadata": {
        "id": "QKdItdiFQA2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Support Vector Machine for Regression (SVR)\n",
        "\n",
        "Selain klasifikasi, SVM juga dapat digunakan untuk regresi. Pendekatan ini dikenal sebagai Support Vector Regression (SVR), yang berfokus pada pencarian fungsi regresi yang berada dalam batas toleransi tertentu terhadap data training.\n"
      ],
      "metadata": {
        "id": "feH3evd0QB3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "\n",
        "svm_reg = LinearSVR(epsilon=1.5)\n",
        "svm_reg.fit(X, y.ravel())\n"
      ],
      "metadata": {
        "id": "YaGHfSN7QDFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "svm_poly_reg = SVR(kernel=\"poly\", degree=2, C=100, epsilon=0.1)\n",
        "svm_poly_reg.fit(X, y.ravel())\n"
      ],
      "metadata": {
        "id": "u4Xv7sEyQEMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Closing Summary (Chapter 5)\n",
        "\n",
        "Chapter ini membahas Support Vector Machines sebagai algoritma yang kuat dan serbaguna. Konsep utama yang dipelajari meliputi large margin classification, soft margin, penggunaan kernel untuk menangani non-linearitas, serta penerapan SVM pada klasifikasi dan regresi.\n",
        "\n",
        "Pemahaman terhadap margin, kernel, dan regularization menjadi bekal penting untuk memahami model Machine Learning lanjutan pada chapter berikutnya.\n"
      ],
      "metadata": {
        "id": "mgiQz7VlQFa3"
      }
    }
  ]
}