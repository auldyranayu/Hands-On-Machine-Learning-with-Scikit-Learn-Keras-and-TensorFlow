{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 15: Processing Sequences Using RNNs and CNNs\n",
        "\n",
        "Bab ini membahas pendekatan Deep Learning untuk menangani **data berurutan (sequential data)**, seperti data waktu (time series), teks, dan sinyal audio. Pada jenis data ini, urutan dan konteks antar elemen memiliki peran yang sangat penting.\n",
        "\n",
        "Berbeda dengan jaringan saraf feedforward biasa yang mengasumsikan setiap input bersifat independen, **Recurrent Neural Networks (RNN)** dirancang untuk memproses data secara berurutan. RNN memiliki mekanisme *state internal* yang memungkinkan informasi dari masa lalu memengaruhi prediksi di masa sekarang.\n",
        "\n",
        "## Mengapa Model Sekuensial Penting?\n",
        "\n",
        "Banyak permasalahan dunia nyata tidak dapat diselesaikan dengan baik tanpa mempertimbangkan urutan data. Beberapa contoh aplikasi utama meliputi:\n",
        "- **Time Series Forecasting**: prediksi harga saham, cuaca, beban listrik, dan permintaan produk.\n",
        "- **Natural Language Processing (NLP)**: terjemahan otomatis, analisis sentimen, ringkasan teks, dan chatbot.\n",
        "- **Audio & Speech Processing**: pengenalan suara, musik, dan sinyal audio lainnya.\n",
        "\n",
        "## Daftar Isi:\n",
        "1. Konsep dasar Recurrent Neural Networks\n",
        "2. Pelatihan RNN dan Backpropagation Through Time\n",
        "3. Peramalan time series menggunakan RNN\n",
        "4. Masalah memori jangka pendek pada RNN\n",
        "5. LSTM dan GRU sebagai solusi memori jangka panjang\n",
        "6. CNN 1D sebagai alternatif pemrosesan urutan\n",
        "7. Arsitektur WaveNet untuk data audio\n"
      ],
      "metadata": {
        "id": "fx0odTyLnBLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Bagaimana Recurrent Neural Networks Bekerja?\n",
        "\n",
        "Pada setiap langkah waktu ke-$t$, sebuah neuron rekuren menerima dua informasi:\n",
        "- Input saat ini $x_{(t)}$\n",
        "- Hidden state dari langkah waktu sebelumnya $h_{(t-1)}$\n",
        "\n",
        "Hidden state ini berfungsi sebagai bentuk *memori*, yang membawa informasi dari masa lalu ke masa sekarang. Dengan mekanisme ini, RNN mampu mempelajari ketergantungan temporal dalam data.\n",
        "\n",
        "### Dimensi Input pada RNN\n",
        "\n",
        "Lapisan RNN di Keras mengharapkan input berbentuk tensor 3 dimensi, yaitu:\n",
        "\n"
      ],
      "metadata": {
        "id": "_6gXAPYOnEAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Penjelasan:\n",
        "- **batch_size**: jumlah sampel dalam satu batch training.\n",
        "- **time_steps**: panjang urutan data (misalnya 30 hari terakhir).\n",
        "- **dimensionality**: jumlah fitur pada setiap langkah waktu.\n",
        "\n",
        "Memahami struktur ini sangat penting agar data dapat diberikan ke model dengan benar.\n"
      ],
      "metadata": {
        "id": "cqKmrhyDnFLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# Contoh RNN Sederhana\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
        "    keras.layers.SimpleRNN(20),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "print(\"Model RNN dengan 2 lapisan rekuren berhasil didefinisikan.\")\n"
      ],
      "metadata": {
        "id": "CxlhCbYDnGDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Peramalan Time Series (Forecasting)\n",
        "\n",
        "Salah satu penggunaan paling umum dari RNN adalah **peramalan time series**, yaitu memprediksi nilai di masa depan berdasarkan data historis.\n",
        "\n",
        "Sebelum membangun model kompleks, sangat penting untuk menetapkan **baseline model**, antara lain:\n",
        "1. **Naive Forecasting**: asumsi bahwa nilai berikutnya sama dengan nilai terakhir.\n",
        "2. **Model Linear**: seperti regresi linear untuk menangkap tren sederhana.\n",
        "\n",
        "Baseline ini berfungsi sebagai pembanding agar kita dapat memastikan bahwa model Deep Learning benar-benar belajar pola yang bermakna.\n",
        "\n",
        "### Deep RNN vs Simple RNN\n",
        "\n",
        "Deep RNN dibangun dengan menumpuk beberapa lapisan RNN. Pada arsitektur ini, parameter `return_sequences=True` wajib digunakan pada semua lapisan kecuali lapisan terakhir, agar output berupa urutan lengkap dapat diteruskan ke lapisan berikutnya.\n"
      ],
      "metadata": {
        "id": "pZX6XrA2nHAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membangun Deep RNN untuk peramalan\n",
        "model_deep = keras.models.Sequential([\n",
        "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
        "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(10)) # Memprediksi 10 langkah ke depan sekaligus\n",
        "])\n",
        "\n",
        "model_deep.summary()\n"
      ],
      "metadata": {
        "id": "yw0moJs0nINb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Masalah Short-Term Memory pada RNN\n",
        "\n",
        "RNN standar seperti `SimpleRNN` sering mengalami masalah **vanishing gradients**, terutama ketika harus mempelajari urutan yang panjang. Akibatnya, informasi dari awal urutan cenderung hilang selama proses training.\n",
        "\n",
        "Untuk mengatasi keterbatasan ini, dikembangkan arsitektur RNN yang lebih canggih.\n",
        "\n",
        "### Long Short-Term Memory (LSTM)\n",
        "\n",
        "LSTM memperkenalkan *cell state* sebagai jalur memori jangka panjang yang relatif stabil. Informasi dalam cell state dikontrol oleh tiga gerbang:\n",
        "- **Forget Gate**: menentukan informasi mana yang harus dilupakan.\n",
        "- **Input Gate**: menentukan informasi baru yang akan disimpan.\n",
        "- **Output Gate**: menentukan informasi yang akan dikeluarkan sebagai output.\n",
        "\n",
        "### Gated Recurrent Unit (GRU)\n",
        "\n",
        "GRU merupakan versi yang lebih sederhana dari LSTM dengan jumlah parameter lebih sedikit. Meskipun lebih ringan, performa GRU sering kali sebanding dengan LSTM.\n"
      ],
      "metadata": {
        "id": "ZsoPj8p-nJUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan LSTM\n",
        "model_lstm = keras.models.Sequential([\n",
        "    keras.layers.LSTM(50, return_sequences=True, input_shape=[None, 1]),\n",
        "    keras.layers.LSTM(50),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "print(\"Model LSTM siap digunakan untuk urutan panjang.\")\n"
      ],
      "metadata": {
        "id": "i1k9w3d6nKgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. CNN 1D untuk Pemrosesan Urutan\n",
        "\n",
        "Selain RNN, **Convolutional Neural Networks 1D (CNN 1D)** sering digunakan untuk memproses data sekuensial. CNN 1D bekerja dengan meluncurkan filter di sepanjang dimensi waktu untuk mendeteksi pola lokal.\n",
        "\n",
        "Keunggulan CNN 1D:\n",
        "- Proses training lebih cepat karena dapat diparalelkan\n",
        "- Lebih stabil terhadap vanishing gradient\n",
        "- Sangat efektif untuk mendeteksi pola jangka pendek\n",
        "\n",
        "Dalam praktik, CNN 1D sering dikombinasikan dengan RNN untuk mendapatkan manfaat dari kedua pendekatan.\n"
      ],
      "metadata": {
        "id": "LJVUmESInLai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan CNN 1D untuk Time Series\n",
        "model_cnn = keras.models.Sequential([\n",
        "    keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding=\"valid\", input_shape=[None, 1]),\n",
        "    keras.layers.SimpleRNN(20),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_cnn.summary()\n"
      ],
      "metadata": {
        "id": "umDPdPionMff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. WaveNet\n",
        "\n",
        "WaveNet merupakan arsitektur berbasis CNN yang dirancang khusus untuk data audio. Model ini menggunakan **dilated convolutions**, yaitu teknik konvolusi yang memperluas receptive field tanpa menambah jumlah parameter secara signifikan.\n",
        "\n",
        "Dengan pendekatan ini, WaveNet mampu menangkap ketergantungan jangka panjang hingga ribuan langkah waktu ke belakang, menjadikannya sangat efektif untuk pemodelan audio resolusi tinggi seperti speech synthesis.\n"
      ],
      "metadata": {
        "id": "NGF_sIHnnNYX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rangkuman Bab 15\n",
        "\n",
        "Beberapa poin penting yang dapat disimpulkan dari bab ini:\n",
        "\n",
        "1. RNN sangat cocok untuk data berurutan, namun `SimpleRNN` terbatas pada urutan pendek.\n",
        "2. Untuk urutan panjang, **LSTM dan GRU** merupakan pilihan yang jauh lebih stabil.\n",
        "3. **CNN 1D** adalah alternatif yang cepat dan sering kali kompetitif untuk time series forecasting.\n",
        "4. Selalu bandingkan performa model dengan **baseline sederhana** seperti naive forecasting.\n",
        "5. Gunakan `TimeDistributed` jika model perlu menghasilkan output pada setiap langkah waktu.\n",
        "\n",
        "Dengan memahami berbagai arsitektur ini, kita dapat memilih pendekatan yang paling sesuai dengan karakteristik data sekuensial yang dihadapi.\n"
      ],
      "metadata": {
        "id": "zpSVZTGunPRW"
      }
    }
  ]
}