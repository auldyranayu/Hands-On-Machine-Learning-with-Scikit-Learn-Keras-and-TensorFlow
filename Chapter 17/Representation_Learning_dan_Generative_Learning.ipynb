{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 17: Representation Learning dan Generative Learning\n",
        "## Autoencoders & Generative Adversarial Networks (GANs)\n",
        "\n",
        "Pada bab ini, kita membahas pendekatan **unsupervised learning** dan **generative modeling**\n",
        "yang bertujuan untuk mempelajari representasi laten (*latent representations*) dari data.\n",
        "Berbeda dengan supervised learning yang bergantung pada label, pendekatan ini berfokus\n",
        "pada struktur internal data itu sendiri.\n",
        "\n",
        "Dua keluarga model utama yang dibahas adalah **Autoencoders** dan\n",
        "**Generative Adversarial Networks (GANs)**.\n",
        "Autoencoder digunakan untuk kompresi, ekstraksi fitur, dan reduksi dimensi,\n",
        "sedangkan GAN digunakan untuk menghasilkan data sintetis yang menyerupai data asli.\n",
        "\n",
        "Pendekatan-pendekatan ini banyak digunakan dalam aplikasi modern seperti:\n",
        "- Pengolahan dan rekonstruksi citra\n",
        "- Deteksi anomali\n",
        "- Data augmentation\n",
        "- Pembuatan konten sintetis (gambar, audio, dan video)\n"
      ],
      "metadata": {
        "id": "dKaxA8cG0qAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fokus Pembelajaran\n",
        "\n",
        "Pada akhir bab ini, pembaca diharapkan mampu:\n",
        "1. Memahami prinsip kerja **Autoencoder** dan efek *bottleneck*.\n",
        "2. Menjelaskan perbedaan **Undercomplete**, **Stacked**, dan **Convolutional Autoencoder**.\n",
        "3. Memahami peran regularisasi melalui **Denoising** dan **Sparse Autoencoder**.\n",
        "4. Menjelaskan konsep probabilistik pada **Variational Autoencoder (VAE)**.\n",
        "5. Memahami dinamika pelatihan **Generative Adversarial Networks (GAN)**.\n",
        "6. Mengenal **DCGAN** sebagai standar GAN berbasis konvolusi untuk citra.\n"
      ],
      "metadata": {
        "id": "06xWH9QF0r27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Undercomplete Autoencoders\n",
        "\n",
        "Undercomplete Autoencoder merupakan bentuk autoencoder paling dasar,\n",
        "di mana dimensi *latent space* (bottleneck) dibuat lebih kecil\n",
        "dibandingkan dengan dimensi input.\n",
        "\n",
        "Dengan keterbatasan ini, jaringan dipaksa untuk mempelajari\n",
        "representasi data yang paling informatif,\n",
        "bukan sekadar menyalin input ke output.\n",
        "Jika seluruh lapisan bersifat linear dan fungsi loss adalah MSE,\n",
        "model ini secara teoritis setara dengan **Principal Component Analysis (PCA)**.\n",
        "\n",
        "Pendekatan ini sering digunakan sebagai langkah awal\n",
        "untuk memahami struktur data berdimensi tinggi.\n"
      ],
      "metadata": {
        "id": "t0Fy_nco0s0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# Membuat data sintetis 3D yang terletak pada manifold 2D\n",
        "def generate_3d_data(m, w1=0.1, w2=0.3, noise=0.1):\n",
        "    angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
        "    data = np.empty((m, 3))\n",
        "    data[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
        "    data[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
        "    data[:, 2] = data[:, 0] * w1 + data[:, 1] * w2 + noise * np.random.randn(m)\n",
        "    return data\n",
        "\n",
        "X_train = generate_3d_data(100)\n",
        "X_train = X_train - X_train.mean(axis=0)\n",
        "\n",
        "# Autoencoder linear dengan bottleneck 2 neuron\n",
        "encoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(2, input_shape=[3])\n",
        "])\n",
        "\n",
        "decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(3, input_shape=[2])\n",
        "])\n",
        "\n",
        "autoencoder = keras.models.Sequential([encoder, decoder])\n",
        "\n",
        "autoencoder.compile(\n",
        "    loss=\"mse\",\n",
        "    optimizer=keras.optimizers.SGD(learning_rate=0.1)\n",
        ")\n",
        "\n",
        "history = autoencoder.fit(X_train, X_train, epochs=20, verbose=0)\n",
        "\n",
        "print(\"Pelatihan Autoencoder selesai. Loss akhir:\", history.history[\"loss\"][-1])\n"
      ],
      "metadata": {
        "id": "3fYSbHwB0t_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Stacked Autoencoders\n",
        "\n",
        "Stacked Autoencoder terdiri dari beberapa lapisan tersembunyi\n",
        "yang memungkinkan model mempelajari representasi yang lebih kompleks dan hierarkis.\n",
        "Setiap lapisan mengekstraksi fitur dari representasi lapisan sebelumnya.\n",
        "\n",
        "Keuntungan utama pendekatan ini adalah fleksibilitas dan daya representasi yang tinggi.\n",
        "Namun, jika kapasitas jaringan terlalu besar,\n",
        "autoencoder dapat mengalami **overfitting**\n",
        "dan hanya menghafal data pelatihan tanpa benar-benar belajar pola yang bermakna.\n",
        "\n",
        "Oleh karena itu, pemilihan arsitektur dan regularisasi menjadi sangat penting.\n"
      ],
      "metadata": {
        "id": "Fgt1q1dj0vGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat dataset Fashion MNIST\n",
        "(X_train_full, _), (X_test, _) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full.astype(np.float32) / 255\n",
        "X_test = X_test.astype(np.float32) / 255\n",
        "\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "\n",
        "def build_stacked_autoencoder():\n",
        "    encoder = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dense(100, activation=\"selu\"),\n",
        "        keras.layers.Dense(30, activation=\"selu\"),\n",
        "    ])\n",
        "\n",
        "    decoder = keras.models.Sequential([\n",
        "        keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
        "        keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "        keras.layers.Reshape([28, 28])\n",
        "    ])\n",
        "\n",
        "    return keras.models.Sequential([encoder, decoder])\n",
        "\n",
        "stacked_ae = build_stacked_autoencoder()\n",
        "stacked_ae.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=keras.optimizers.SGD(learning_rate=1.5)\n",
        ")\n",
        "\n",
        "print(\"Stacked Autoencoder berhasil dibangun.\")\n"
      ],
      "metadata": {
        "id": "AJsKRBzS0wMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Convolutional Autoencoders\n",
        "\n",
        "Convolutional Autoencoder dirancang khusus untuk data citra.\n",
        "Alih-alih menggunakan lapisan Dense,\n",
        "model ini memanfaatkan **Conv2D** pada encoder\n",
        "dan **Conv2DTranspose** pada decoder.\n",
        "\n",
        "Pendekatan ini mempertahankan struktur spasial gambar\n",
        "dan umumnya menghasilkan rekonstruksi yang jauh lebih baik\n",
        "dibanding autoencoder berbasis fully-connected.\n"
      ],
      "metadata": {
        "id": "obm9XTA_0xZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv_encoder = keras.models.Sequential([\n",
        "    keras.layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n",
        "    keras.layers.Conv2D(16, 3, padding=\"same\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(2),\n",
        "    keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(2),\n",
        "    keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(2)\n",
        "])\n",
        "\n",
        "conv_decoder = keras.models.Sequential([\n",
        "    keras.layers.Conv2DTranspose(32, 3, strides=2, padding=\"valid\", activation=\"selu\", input_shape=[3, 3, 64]),\n",
        "    keras.layers.Conv2DTranspose(16, 3, strides=2, padding=\"same\", activation=\"selu\"),\n",
        "    keras.layers.Conv2DTranspose(1, 3, strides=2, padding=\"same\", activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "\n",
        "conv_ae = keras.models.Sequential([conv_encoder, conv_decoder])\n",
        "conv_ae.summary()\n"
      ],
      "metadata": {
        "id": "lSNJyKlf0yjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Variational Autoencoders (VAE)\n",
        "\n",
        "Berbeda dengan autoencoder klasik,\n",
        "Variational Autoencoder (VAE) mempelajari\n",
        "distribusi probabilitas pada latent space,\n",
        "bukan sekadar satu titik deterministik.\n",
        "\n",
        "Pendekatan ini memungkinkan kita\n",
        "melakukan *sampling* untuk menghasilkan data baru.\n",
        "VAE menjadi fondasi penting bagi banyak model generatif modern,\n",
        "meskipun hasil rekonstruksinya cenderung lebih halus (blur).\n"
      ],
      "metadata": {
        "id": "7Prgyg2e0zfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Generative Adversarial Networks (GANs)\n",
        "\n",
        "GAN merupakan pendekatan generatif berbasis permainan dua pemain (*two-player game*).\n",
        "Model ini terdiri dari:\n",
        "- **Generator**, yang berusaha menciptakan data palsu menyerupai data asli.\n",
        "- **Discriminator**, yang bertugas membedakan data asli dan data palsu.\n",
        "\n",
        "Kedua jaringan dilatih secara bersamaan dalam skema kompetitif,\n",
        "di mana peningkatan performa satu model\n",
        "akan memaksa model lainnya untuk ikut membaik.\n"
      ],
      "metadata": {
        "id": "sAc98UEh00ao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codings_size = 30\n",
        "\n",
        "generator = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n",
        "    keras.layers.Dense(150, activation=\"selu\"),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "\n",
        "discriminator = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(150, activation=\"selu\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "discriminator.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"rmsprop\"\n",
        ")\n",
        "\n",
        "discriminator.trainable = False\n",
        "\n",
        "gan = keras.models.Sequential([generator, discriminator])\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "\n",
        "print(\"Model GAN dasar berhasil didefinisikan.\")\n"
      ],
      "metadata": {
        "id": "HosmPeaC01cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Tantangan Melatih GAN\n",
        "\n",
        "Meskipun sangat kuat, GAN terkenal sulit untuk dilatih.\n",
        "Beberapa tantangan utama meliputi:\n",
        "1. **Mode Collapse**: Generator hanya menghasilkan satu jenis output.\n",
        "2. **Ketidakseimbangan Pelatihan**: Discriminator terlalu kuat atau terlalu lemah.\n",
        "3. **Instabilitas Loss**: Loss tidak selalu mencerminkan kualitas hasil.\n",
        "\n",
        "Berbagai teknik seperti DCGAN, WGAN, dan spectral normalization\n",
        "dikembangkan untuk mengatasi masalah ini.\n"
      ],
      "metadata": {
        "id": "YjGLlVJj02lk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kesimpulan Praktis\n",
        "\n",
        "- Autoencoder sangat berguna untuk reduksi dimensi dan ekstraksi fitur.\n",
        "- VAE memungkinkan eksplorasi latent space secara probabilistik.\n",
        "- GAN mampu menghasilkan data sintetis yang sangat realistis.\n",
        "- Namun, GAN membutuhkan strategi pelatihan yang hati-hati.\n"
      ],
      "metadata": {
        "id": "ZqLzbaOK04GH"
      }
    }
  ]
}