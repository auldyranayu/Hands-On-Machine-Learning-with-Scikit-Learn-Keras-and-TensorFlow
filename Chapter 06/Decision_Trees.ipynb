{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 6: Decision Trees\n",
        "\n",
        "Decision Tree merupakan salah satu algoritma Machine Learning yang paling mudah dipahami secara konseptual. Model ini meniru proses pengambilan keputusan manusia dengan membagi data ke dalam serangkaian aturan berbasis kondisi.\n",
        "\n",
        "Decision Tree dapat digunakan untuk berbagai jenis tugas, antara lain:\n",
        "- classification,\n",
        "- regression,\n",
        "- serta permasalahan multi-output.\n",
        "\n",
        "Meskipun sederhana secara konsep, Decision Tree mampu memodelkan hubungan yang kompleks pada data. Selain itu, algoritma ini menjadi fondasi bagi metode ensemble populer seperti Random Forest dan Gradient Boosting, sehingga pemahaman terhadap Decision Tree sangat penting.\n"
      ],
      "metadata": {
        "id": "depbs6-GT4yR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Training and Visualizing a Decision Tree\n",
        "\n",
        "Untuk mempelajari prinsip kerja **Decision Tree**, kita akan melatih sebuah model menggunakan **dataset Iris**, yang dikenal sederhana dan sering dijadikan dataset contoh dalam Machine Learning.\n",
        "\n",
        "Agar struktur pohon lebih mudah dianalisis, hanya dua fitur yang digunakan dalam eksperimen ini, yaitu:\n",
        "- panjang kelopak bunga (petal length)\n",
        "- lebar kelopak bunga (petal width)\n",
        "\n",
        "Pembatasan jumlah fitur ini membantu kita melihat dengan jelas bagaimana Decision Tree membentuk aturan keputusan berdasarkan batas nilai tertentu pada setiap fitur.\n",
        "\n"
      ],
      "metadata": {
        "id": "zlvJCx4hT7rf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPbv78FmT201"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data[:, 2:]  # petal length and petal width\n",
        "y = iris.target\n",
        "\n",
        "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
        "tree_clf.fit(X, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Decision Tree di atas dibatasi dengan parameter `max_depth=2`. Pembatasan ini bertujuan agar struktur pohon tetap dangkal dan mudah diinterpretasikan.\n",
        "\n",
        "Tanpa pembatasan kedalaman, Decision Tree cenderung tumbuh sangat kompleks dan berisiko tinggi mengalami overfitting terhadap data training.\n",
        "\n"
      ],
      "metadata": {
        "id": "Qu5sk07AUAid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Visualizing the Decision Tree\n",
        "\n",
        "Salah satu keunggulan utama Decision Tree adalah kemampuannya untuk divisualisasikan. Visualisasi ini memungkinkan kita melihat aturan keputusan yang dipelajari oleh model secara eksplisit.\n"
      ],
      "metadata": {
        "id": "vZg8uj-VULLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "export_graphviz(\n",
        "    tree_clf,\n",
        "    out_file=\"iris_tree.dot\",\n",
        "    feature_names=iris.feature_names[2:],\n",
        "    class_names=iris.target_names,\n",
        "    rounded=True,\n",
        "    filled=True\n",
        ")"
      ],
      "metadata": {
        "id": "XrOy6sh4UNSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "File `.dot` yang dihasilkan dapat dikonversi menjadi gambar menggunakan Graphviz.\n",
        "\n",
        "Visualisasi pohon menunjukkan bagaimana Decision Tree membagi ruang fitur berdasarkan nilai threshold tertentu, mulai dari root node hingga leaf node, sebagaimana ditunjukkan pada ilustrasi di buku.\n"
      ],
      "metadata": {
        "id": "nGT6H_PZUPvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. How Decision Trees Make Predictions\n",
        "\n",
        "Decision Tree menghasilkan prediksi dengan menelusuri struktur pohon dari root node menuju leaf node. Setiap node internal berisi aturan keputusan berbentuk kondisi logis.\n"
      ],
      "metadata": {
        "id": "-kFsxP5RUTZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Traversing the Tree\n",
        "\n",
        "Setiap node internal pada Decision Tree berisi pertanyaan sederhana, misalnya:\n",
        "\n",
        "- Apakah petal length â‰¤ 2.45?\n",
        "\n",
        "Jika kondisi bernilai benar, instance diarahkan ke cabang kiri; jika salah, ke cabang kanan. Proses ini berulang hingga mencapai leaf node.\n"
      ],
      "metadata": {
        "id": "4LiEncx1UUqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Node Information Explained\n",
        "\n",
        "Setiap node pada visualisasi Decision Tree biasanya menampilkan informasi berikut:\n",
        "- **gini**: tingkat ketidakmurnian kelas pada node\n",
        "- **samples**: jumlah data yang mencapai node\n",
        "- **value**: distribusi jumlah data pada tiap kelas\n",
        "- **class**: kelas mayoritas pada node\n",
        "\n",
        "Informasi ini membantu kita memahami keputusan yang diambil model.\n"
      ],
      "metadata": {
        "id": "EtsGq3YCUZNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Gini Impurity\n",
        "\n",
        "Gini impurity mengukur seberapa besar kemungkinan sebuah instance salah diklasifikasikan jika label dipilih secara acak berdasarkan distribusi kelas pada node tersebut.\n",
        "\n",
        "- Nilai 0 menunjukkan node sepenuhnya murni\n",
        "- Nilai yang lebih besar menunjukkan kelas yang semakin bercampur\n",
        "\n",
        "Decision Tree berusaha memilih split yang meminimalkan nilai Gini impurity.\n"
      ],
      "metadata": {
        "id": "iTpUmXzWUa6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Contoh Konseptual Proses Prediksi\n",
        "\n",
        "Untuk memahami bagaimana Decision Tree menghasilkan sebuah prediksi, kita dapat meninjau alur pengambilan keputusan secara konseptual pada satu instance data.\n",
        "\n",
        "Misalkan kita memiliki sebuah bunga Iris dengan karakteristik sebagai berikut:\n",
        "\n",
        "- panjang petal (petal length) = 5.0\n",
        "- lebar petal (petal width) = 1.5\n",
        "\n",
        "Proses prediksi dimulai dari **root node** pada pohon keputusan. Pada node ini, model mengevaluasi sebuah kondisi berbentuk pertanyaan, misalnya apakah nilai panjang petal lebih kecil atau sama dengan suatu ambang batas tertentu.\n",
        "\n",
        "Jika kondisi tersebut terpenuhi, instance akan diarahkan ke cabang kiri. Jika tidak, instance akan mengikuti cabang kanan. Proses evaluasi kondisi ini berlangsung secara berurutan pada setiap node internal yang dilewati.\n",
        "\n",
        "Alur traversal tersebut terus berlanjut hingga instance mencapai sebuah **leaf node**. Leaf node tidak lagi berisi pertanyaan, melainkan hasil keputusan akhir berupa kelas yang diprediksi.\n",
        "\n",
        "Kelas yang dipilih umumnya adalah **kelas mayoritas** dari seluruh instance training yang berada pada leaf node tersebut. Dengan cara ini, Decision Tree mengubah serangkaian aturan sederhana menjadi sebuah keputusan klasifikasi yang dapat diinterpretasikan secara jelas.\n"
      ],
      "metadata": {
        "id": "IJabJT0BUbwk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5 Predicting Class Probabilities\n",
        "\n",
        "Selain menghasilkan label kelas, Decision Tree juga mampu memberikan estimasi probabilitas kelas. Probabilitas ini dihitung berdasarkan proporsi data pada leaf node tempat instance berakhir.\n"
      ],
      "metadata": {
        "id": "S_37g7WkV2Gx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree_clf.predict_proba([[5, 1.5]])\n"
      ],
      "metadata": {
        "id": "jj3G9ZkXV-Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Estimating Class Probabilities\n",
        "\n",
        "Probabilitas kelas dihitung berdasarkan distribusi data pada leaf node tempat sebuah instance berakhir.\n",
        "\n",
        "Jika sebuah leaf node hanya berisi satu kelas, probabilitas kelas tersebut adalah 100%. Jika berisi beberapa kelas, probabilitas dihitung berdasarkan proporsinya.\n"
      ],
      "metadata": {
        "id": "_BpKA1MfV-_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. The CART Training Algorithm\n",
        "\n",
        "Scikit-Learn menggunakan algoritma CART (Classification and Regression Trees) untuk melatih Decision Tree.\n",
        "\n",
        "CART bekerja dengan mencari split terbaik pada setiap node yang menghasilkan pemisahan data paling murni berdasarkan kriteria tertentu.\n"
      ],
      "metadata": {
        "id": "1IMTmRH1WBPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree_clf_entropy = DecisionTreeClassifier(criterion=\"entropy\", max_depth=2)\n",
        "tree_clf_entropy.fit(X, y)\n"
      ],
      "metadata": {
        "id": "Kmh06teSWC4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Regularization Hyperparameters\n",
        "\n",
        "Decision Tree sangat rentan terhadap overfitting jika dibiarkan tumbuh tanpa batas. Oleh karena itu, tersedia berbagai hyperparameter untuk membatasi kompleksitas model.\n"
      ],
      "metadata": {
        "id": "OW6I5-8SWDnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree_clf_reg = DecisionTreeClassifier(\n",
        "    max_depth=3,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "tree_clf_reg.fit(X, y)\n"
      ],
      "metadata": {
        "id": "vsQOXUMzWHlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Meskipun Decision Tree memiliki keunggulan dalam hal interpretabilitas dan kemudahan pemahaman, algoritma ini juga memiliki kelemahan yang cukup signifikan, yaitu **ketidakstabilan model**.\n",
        "\n",
        "Decision Tree sangat bergantung pada data training yang digunakan. Perubahan kecil pada data, baik pada nilai fitur maupun jumlah sampel, dapat menghasilkan struktur pohon yang sangat berbeda. Hal ini menyebabkan performa model menjadi kurang konsisten ketika diterapkan pada data yang sedikit berbeda.\n",
        "\n",
        "Masalah instabilitas ini berkaitan erat dengan cara Decision Tree membangun model, yaitu dengan memilih split terbaik secara lokal pada setiap node, tanpa mempertimbangkan dampaknya terhadap keseluruhan struktur pohon.\n"
      ],
      "metadata": {
        "id": "tDuwQVQiW9EU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1 Sensitivity to Data Variations\n",
        "\n",
        "Decision Tree sangat sensitif terhadap variasi data. Penambahan, penghapusan, atau perubahan kecil pada beberapa instance data dapat mengubah split awal pada root node.\n",
        "\n",
        "Karena split awal memiliki pengaruh besar terhadap seluruh percabangan berikutnya, perubahan kecil tersebut dapat menyebabkan struktur pohon yang dihasilkan menjadi sangat berbeda, meskipun perbedaan data relatif kecil.\n",
        "\n",
        "Akibatnya, Decision Tree memiliki **variance yang tinggi**, yaitu performa model dapat berubah secara signifikan ketika dilatih pada dataset yang sedikit berbeda.\n"
      ],
      "metadata": {
        "id": "MVxTvXk-W_XG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ad20ZQwOWF4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 Sensitivity to Axis Orientation\n",
        "\n",
        "Selain sensitif terhadap variasi data, Decision Tree juga sensitif terhadap orientasi sumbu fitur.\n",
        "\n",
        "Decision Tree hanya mampu membuat pemisahan data yang sejajar dengan sumbu fitur (axis-aligned splits). Jika data mengalami rotasi atau transformasi linier, Decision Tree mungkin memerlukan lebih banyak split untuk mencapai pemisahan yang baik.\n",
        "\n",
        "Hal ini dapat menyebabkan pohon menjadi lebih dalam dan kompleks, yang pada akhirnya meningkatkan risiko overfitting.\n",
        "\n",
        "Keterbatasan ini menjadi salah satu alasan utama mengapa metode ensemble seperti **Random Forest** dan **Gradient Boosting** dikembangkan, karena metode tersebut mampu mengurangi ketergantungan pada satu struktur pohon saja.\n"
      ],
      "metadata": {
        "id": "A4pKOe7fXBwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Closing Summary (Chapter 6)\n",
        "\n",
        "Pada Chapter 6, kita telah mempelajari Decision Trees sebagai algoritma Machine Learning yang sederhana namun sangat powerful.\n",
        "\n",
        "Beberapa poin penting yang dibahas dalam chapter ini meliputi:\n",
        "\n",
        "- proses pelatihan dan visualisasi Decision Tree,\n",
        "- mekanisme pengambilan keputusan dan prediksi probabilitas kelas,\n",
        "- penggunaan kriteria pemisahan seperti Gini impurity dan entropy,\n",
        "- peran hyperparameter regularization dalam mengontrol kompleksitas model,\n",
        "- serta keterbatasan Decision Tree terkait stabilitas dan sensitivitas terhadap data.\n",
        "\n",
        "Meskipun Decision Tree memiliki kelemahan berupa variance yang tinggi, algoritma ini tetap menjadi fondasi penting bagi banyak metode Machine Learning modern.\n"
      ],
      "metadata": {
        "id": "4MTjOZdCXH6S"
      }
    }
  ]
}