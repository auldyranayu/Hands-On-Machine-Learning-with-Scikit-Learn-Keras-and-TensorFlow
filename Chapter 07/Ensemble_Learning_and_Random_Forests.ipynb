{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 7: Ensemble Learning dan Random Forests\n",
        "\n",
        "Bab ini membahas pendekatan *Ensemble Learning*, yaitu teknik Machine Learning yang menggabungkan beberapa model untuk meningkatkan akurasi dan stabilitas prediksi. Pendekatan ini banyak digunakan dalam sistem produksi dan kompetisi Machine Learning karena mampu mengurangi kesalahan generalisasi.\n",
        "\n",
        "Alih-alih mengandalkan satu model tunggal, Ensemble Learning memanfaatkan kekuatan kolektif dari beberapa model yang memiliki karakteristik berbeda.\n"
      ],
      "metadata": {
        "id": "7s67k7YATvDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Konsep Dasar Ensemble Learning\n",
        "\n",
        "Ensemble Learning didasarkan pada prinsip bahwa sekumpulan model yang beragam sering kali mampu menghasilkan prediksi yang lebih baik dibandingkan satu model tunggal.\n",
        "\n",
        "Dalam Ensemble Learning:\n",
        "- Model individual disebut *base learner*\n",
        "- Gabungan beberapa model disebut *ensemble*\n",
        "- Prediksi akhir diperoleh melalui agregasi hasil prediksi\n"
      ],
      "metadata": {
        "id": "khaEM5HUTx0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Weak Learner dan Strong Learner\n",
        "\n",
        "Weak learner adalah model dengan performa sedikit lebih baik dari tebakan acak. Meskipun lemah secara individual, kombinasi banyak weak learner dapat menghasilkan strong learner yang sangat akurat.\n",
        "\n",
        "Keberhasilan pendekatan ini sangat bergantung pada keberagaman kesalahan antar model.\n"
      ],
      "metadata": {
        "id": "Sn91XFOLT2Qo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Voting Classifier\n",
        "\n",
        "Voting Classifier merupakan bentuk Ensemble Learning paling sederhana. Beberapa model dilatih secara terpisah, kemudian prediksinya digabungkan menggunakan mekanisme pemungutan suara.\n"
      ],
      "metadata": {
        "id": "WzmrAU_UT5e7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "rf_clf = RandomForestClassifier()\n",
        "svm_clf = SVC()\n",
        "\n",
        "voting_hard = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('lr', log_reg),\n",
        "        ('rf', rf_clf),\n",
        "        ('svm', svm_clf)\n",
        "    ],\n",
        "    voting='hard'\n",
        ")\n"
      ],
      "metadata": {
        "id": "Ck_IDjavT65m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Evaluasi Voting Classifier\n",
        "\n",
        "Untuk mengevaluasi performa Voting Classifier, digunakan dataset sintetis dan metrik akurasi.\n"
      ],
      "metadata": {
        "id": "UUBrszjLT8yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = make_moons(n_samples=10000, noise=0.35, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "for model in (log_reg, rf_clf, svm_clf, voting_hard):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(model.__class__.__name__, accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "UyRlb0o7T8Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Soft Voting\n",
        "\n",
        "Soft voting menggunakan probabilitas prediksi dari setiap model. Probabilitas tersebut dirata-ratakan, dan kelas dengan probabilitas tertinggi dipilih sebagai hasil akhir.\n"
      ],
      "metadata": {
        "id": "U09dHgKtUDWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_clf = SVC(probability=True)\n",
        "\n",
        "voting_soft = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('lr', log_reg),\n",
        "        ('rf', rf_clf),\n",
        "        ('svm', svm_clf)\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n"
      ],
      "metadata": {
        "id": "TBJ544yXUGBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Bagging dan Pasting\n",
        "\n",
        "Bagging dan Pasting merupakan teknik Ensemble Learning yang meningkatkan diversitas model dengan melatih setiap model pada subset data yang berbeda.\n"
      ],
      "metadata": {
        "id": "00ue0zVTUHXf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Bagging (Bootstrap Aggregating)\n",
        "\n",
        "Bagging menggunakan teknik sampling dengan pengembalian (bootstrap). Akibatnya, satu data dapat muncul lebih dari satu kali dalam satu subset.\n",
        "\n",
        "Pendekatan ini efektif untuk mengurangi variance, terutama pada model yang tidak stabil seperti Decision Tree.\n"
      ],
      "metadata": {
        "id": "d2AKQwI0W9Rq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Pasting\n",
        "\n",
        "Pasting menggunakan sampling tanpa pengembalian. Setiap subset data berisi instance yang unik.\n",
        "\n",
        "Dibandingkan Bagging, Pasting cenderung menghasilkan model dengan tingkat keberagaman yang lebih rendah.\n"
      ],
      "metadata": {
        "id": "DreV8EwWXAgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Bagging with Scikit-Learn\n",
        "\n",
        "Scikit-Learn menyediakan class `BaggingClassifier` untuk mengimplementasikan teknik Bagging secara langsung.\n"
      ],
      "metadata": {
        "id": "l2bO3O_RXCAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(),\n",
        "    n_estimators=500,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "bag_clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "0gsh_7gFXEA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 Training and Evaluating Bagging Classifier\n",
        "\n",
        "Setelah model dilatih, performanya dievaluasi menggunakan data test untuk melihat peningkatan akurasi dibandingkan Decision Tree tunggal.\n"
      ],
      "metadata": {
        "id": "YTQfdjz3XF8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_bag = bag_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred_bag)\n"
      ],
      "metadata": {
        "id": "2GVOB3VHXHfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Out-of-Bag (OOB) Evaluation\n",
        "\n",
        "Out-of-Bag evaluation memungkinkan estimasi performa model tanpa validation set terpisah, dengan memanfaatkan data yang tidak terpilih selama proses bootstrap sampling.\n"
      ],
      "metadata": {
        "id": "ivThaTR8UNrj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Apa itu Out-of-Bag Samples?\n",
        "\n",
        "Pada setiap bootstrap sampling, sekitar 37% data tidak terpilih. Data ini disebut out-of-bag samples dan dapat digunakan untuk evaluasi model.\n"
      ],
      "metadata": {
        "id": "0TLC_z8JXN2g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Mengaktifkan OOB Evaluation di Scikit-Learn\n",
        "\n",
        "OOB evaluation dapat diaktifkan dengan mengatur parameter `oob_score=True`.\n"
      ],
      "metadata": {
        "id": "MyQ7H9U5XPFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_oob = BaggingClassifier(\n",
        "    DecisionTreeClassifier(),\n",
        "    n_estimators=500,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    oob_score=True,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "bag_oob.fit(X_train, y_train)\n",
        "bag_oob.oob_score_\n"
      ],
      "metadata": {
        "id": "Sh04u9ZrXQRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Random Forest\n",
        "\n",
        "Random Forest merupakan ensemble Decision Tree yang dilatih menggunakan Bagging dengan tambahan randomisasi fitur pada setiap split.\n"
      ],
      "metadata": {
        "id": "qHHA2UNdUQ2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Mengapa Random Forest Bekerja dengan Baik?\n",
        "\n",
        "Decision Tree tunggal cenderung mengalami overfitting karena sangat sensitif terhadap variasi data.\n",
        "Random Forest mengatasi masalah ini dengan dua mekanisme utama:\n",
        "\n",
        "1. **Bootstrap sampling**: setiap pohon dilatih pada subset data yang berbeda.\n",
        "2. **Random feature selection**: setiap split hanya mempertimbangkan sebagian fitur secara acak.\n",
        "\n",
        "Kombinasi ini menghasilkan pohon-pohon yang tidak saling berkorelasi kuat, sehingga prediksi gabungannya menjadi lebih stabil dan akurat.\n"
      ],
      "metadata": {
        "id": "qf2g7p3eXs2R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Random Forest for Classification\n",
        "\n",
        "Pada tugas klasifikasi, Random Forest menggabungkan prediksi dari setiap pohon menggunakan mekanisme majority voting.\n",
        "Kelas yang paling sering diprediksi oleh seluruh pohon akan dipilih sebagai hasil akhir.\n"
      ],
      "metadata": {
        "id": "4EBm9KpFXuY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=500,\n",
        "    max_leaf_nodes=16,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "KhBjRWa-Xv_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 Evaluating the Random Forest\n",
        "\n",
        "Setelah model Random Forest dilatih, performanya dievaluasi menggunakan data test untuk mengukur kemampuan generalisasi model.\n"
      ],
      "metadata": {
        "id": "BulcgKu0X5WI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred_rf)\n"
      ],
      "metadata": {
        "id": "OFT_65qCX8hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4 Random Forest vs Bagging\n",
        "\n",
        "Random Forest pada dasarnya adalah Bagging Decision Tree dengan tambahan randomisasi fitur.\n",
        "Perbedaan utamanya adalah:\n",
        "\n",
        "- **Bagging**: menggunakan seluruh fitur pada setiap split.\n",
        "- **Random Forest**: hanya menggunakan subset fitur secara acak.\n",
        "\n",
        "Randomisasi fitur ini meningkatkan diversitas antar pohon dan umumnya menghasilkan performa yang lebih baik.\n"
      ],
      "metadata": {
        "id": "rekY_2fhX9cr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Boosting\n",
        "\n",
        "Boosting melatih model secara berurutan, di mana setiap model baru berfokus memperbaiki kesalahan model sebelumnya.\n"
      ],
      "metadata": {
        "id": "f0X4PbM1UTQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Perbedaan Extra-Trees dan Random Forest\n",
        "\n",
        "Perbedaan utama antara kedua metode ini adalah:\n",
        "\n",
        "- Random Forest mencari threshold terbaik pada subset fitur.\n",
        "- Extra-Trees memilih threshold secara acak tanpa optimasi.\n",
        "\n",
        "Akibatnya, Extra-Trees:\n",
        "- lebih cepat dilatih,\n",
        "- memiliki bias sedikit lebih tinggi,\n",
        "- tetapi variansi yang lebih rendah.\n"
      ],
      "metadata": {
        "id": "GeVSCGCCYHJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2 Training an Extra-Trees Classifier\n",
        "\n",
        "Scikit-Learn menyediakan class `ExtraTreesClassifier` untuk mengimplementasikan metode ini.\n"
      ],
      "metadata": {
        "id": "rOaSaEUoYJeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "extra_clf = ExtraTreesClassifier(\n",
        "    n_estimators=500,\n",
        "    max_leaf_nodes=16,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "extra_clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "CN70F3q9YKmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.3 Evaluating Extra-Trees\n",
        "\n",
        "Performa Extra-Trees dievaluasi menggunakan data test untuk dibandingkan dengan Random Forest.\n"
      ],
      "metadata": {
        "id": "94u_MrB-YLpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_extra = extra_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred_extra)\n"
      ],
      "metadata": {
        "id": "1kY2xwnbYOsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.4 Feature Importance\n",
        "\n",
        "Random Forest dan Extra-Trees mampu mengestimasi tingkat kepentingan setiap fitur berdasarkan kontribusinya dalam mengurangi impurity.\n",
        "Informasi ini sangat berguna untuk interpretasi model dan feature selection.\n"
      ],
      "metadata": {
        "id": "LreH-fUoYPop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf.feature_importances_\n"
      ],
      "metadata": {
        "id": "6rPr-VguYQ89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Boosting\n",
        "\n",
        "Boosting merupakan teknik ensemble yang melatih model secara berurutan.\n",
        "Setiap model baru difokuskan untuk memperbaiki kesalahan yang dibuat oleh model sebelumnya.\n"
      ],
      "metadata": {
        "id": "JBuqH-kIYTbl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1 Intuisi Boosting\n",
        "\n",
        "Boosting bekerja dengan memberikan perhatian lebih besar pada data yang sulit diprediksi.\n",
        "Dengan pendekatan ini, sekumpulan weak learner dapat dikombinasikan menjadi model yang sangat kuat.\n"
      ],
      "metadata": {
        "id": "4mYanpjLYUwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 AdaBoost (Adaptive Boosting)\n",
        "\n",
        "AdaBoost merupakan algoritma boosting yang menyesuaikan bobot data secara adaptif.\n",
        "Instance yang salah diprediksi akan diberi bobot lebih besar pada iterasi berikutnya.\n"
      ],
      "metadata": {
        "id": "lfvNUxIkYWC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2.1 Training an AdaBoost Classifier\n",
        "\n",
        "Secara default, AdaBoost menggunakan Decision Tree dengan kedalaman satu sebagai weak learner.\n"
      ],
      "metadata": {
        "id": "vVChxDpCYXR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1),\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "ada_clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "L_XyviaDYYUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2.2 Evaluating AdaBoost\n",
        "\n",
        "Model AdaBoost dievaluasi menggunakan data test untuk mengukur performanya.\n"
      ],
      "metadata": {
        "id": "NDOU0RX9YZko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ada = ada_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred_ada)\n"
      ],
      "metadata": {
        "id": "HXaHEZ9BYau0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.3 Gradient Boosting\n",
        "\n",
        "Gradient Boosting melatih model baru untuk memprediksi residual (kesalahan) dari model sebelumnya.\n",
        "Pendekatan ini mirip dengan optimasi menggunakan gradient descent.\n"
      ],
      "metadata": {
        "id": "TEadLJ_GYb7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.3.1 Intuisi Gradient Boosting\n",
        "\n",
        "Model dilatih secara bertahap, di mana setiap model berusaha meminimalkan kesalahan model sebelumnya.\n",
        "Learning rate digunakan untuk mengontrol kontribusi setiap model baru.\n"
      ],
      "metadata": {
        "id": "mlBkEqYbYeAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.3.2 Training a Gradient Boosting Regressor\n",
        "\n",
        "Contoh berikut menunjukkan penerapan Gradient Boosting untuk masalah regresi.\n"
      ],
      "metadata": {
        "id": "Vr5QY3KqYfkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gbrt = GradientBoostingRegressor(\n",
        "    max_depth=2,\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "gbrt.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "gy1-p04hYg1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Stacking\n",
        "\n",
        "Stacking merupakan teknik ensemble lanjutan yang menggunakan model tingkat kedua (meta-learner)\n",
        "untuk mempelajari cara terbaik menggabungkan prediksi dari beberapa model dasar.\n"
      ],
      "metadata": {
        "id": "IXpxysZHYi6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.1 Intuisi Stacking\n",
        "\n",
        "Prediksi dari model-model dasar digunakan sebagai fitur input bagi meta-learner.\n",
        "Pendekatan ini memungkinkan ensemble belajar bagaimana menimbang kontribusi setiap model.\n"
      ],
      "metadata": {
        "id": "wpXgbqEdYj9W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.2 Stacking in Practice\n",
        "\n",
        "Dalam praktik, meta-learner biasanya menggunakan model sederhana seperti Logistic Regression\n",
        "untuk menjaga kemampuan generalisasi.\n"
      ],
      "metadata": {
        "id": "VxpFmo0lYlJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Closing Summary (Chapter 7)\n",
        "\n",
        "Bab ini membahas berbagai teknik Ensemble Learning, termasuk Voting, Bagging, Random Forest, Boosting, dan Stacking. Pendekatan ini menunjukkan bahwa kombinasi beberapa model yang beragam mampu menghasilkan sistem Machine Learning yang lebih kuat, stabil, dan akurat dibandingkan model tunggal.\n"
      ],
      "metadata": {
        "id": "Ni3dbHHsUVt5"
      }
    }
  ]
}