{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 7: Ensemble Learning dan Random Forests\n",
        "\n",
        "Bab ini membahas pendekatan *Ensemble Learning*, yaitu teknik Machine Learning yang menggabungkan beberapa model untuk meningkatkan akurasi dan stabilitas prediksi. Pendekatan ini banyak digunakan dalam sistem produksi dan kompetisi Machine Learning karena mampu mengurangi kesalahan generalisasi.\n",
        "\n",
        "Alih-alih mengandalkan satu model tunggal, Ensemble Learning memanfaatkan kekuatan kolektif dari beberapa model yang memiliki karakteristik berbeda.\n"
      ],
      "metadata": {
        "id": "7s67k7YATvDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Konsep Dasar Ensemble Learning\n",
        "\n",
        "Ensemble Learning didasarkan pada prinsip bahwa sekumpulan model yang beragam sering kali mampu menghasilkan prediksi yang lebih baik dibandingkan satu model tunggal.\n",
        "\n",
        "Dalam Ensemble Learning:\n",
        "- Model individual disebut *base learner*\n",
        "- Gabungan beberapa model disebut *ensemble*\n",
        "- Prediksi akhir diperoleh melalui agregasi hasil prediksi\n"
      ],
      "metadata": {
        "id": "khaEM5HUTx0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Weak Learner dan Strong Learner\n",
        "\n",
        "Weak learner adalah model dengan performa sedikit lebih baik dari tebakan acak. Meskipun lemah secara individual, kombinasi banyak weak learner dapat menghasilkan strong learner yang sangat akurat.\n",
        "\n",
        "Keberhasilan pendekatan ini sangat bergantung pada keberagaman kesalahan antar model.\n"
      ],
      "metadata": {
        "id": "Sn91XFOLT2Qo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Voting Classifier\n",
        "\n",
        "Voting Classifier merupakan bentuk Ensemble Learning paling sederhana. Beberapa model dilatih secara terpisah, kemudian prediksinya digabungkan menggunakan mekanisme pemungutan suara.\n"
      ],
      "metadata": {
        "id": "WzmrAU_UT5e7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "rf_clf = RandomForestClassifier()\n",
        "svm_clf = SVC()\n",
        "\n",
        "voting_hard = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('lr', log_reg),\n",
        "        ('rf', rf_clf),\n",
        "        ('svm', svm_clf)\n",
        "    ],\n",
        "    voting='hard'\n",
        ")\n"
      ],
      "metadata": {
        "id": "Ck_IDjavT65m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Evaluasi Voting Classifier\n",
        "\n",
        "Untuk mengevaluasi performa Voting Classifier, digunakan dataset sintetis dan metrik akurasi.\n"
      ],
      "metadata": {
        "id": "UUBrszjLT8yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = make_moons(n_samples=10000, noise=0.35, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "for model in (log_reg, rf_clf, svm_clf, voting_hard):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(model.__class__.__name__, accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "UyRlb0o7T8Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Soft Voting\n",
        "\n",
        "Soft voting menggunakan probabilitas prediksi dari setiap model. Probabilitas tersebut dirata-ratakan, dan kelas dengan probabilitas tertinggi dipilih sebagai hasil akhir.\n"
      ],
      "metadata": {
        "id": "U09dHgKtUDWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_clf = SVC(probability=True)\n",
        "\n",
        "voting_soft = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('lr', log_reg),\n",
        "        ('rf', rf_clf),\n",
        "        ('svm', svm_clf)\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n"
      ],
      "metadata": {
        "id": "TBJ544yXUGBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Bagging dan Pasting\n",
        "\n",
        "Bagging dan Pasting merupakan teknik Ensemble Learning yang meningkatkan diversitas model dengan melatih setiap model pada subset data yang berbeda.\n"
      ],
      "metadata": {
        "id": "00ue0zVTUHXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "    base_estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=300,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1\n",
        ")\n"
      ],
      "metadata": {
        "id": "Bhzo2KYuUI8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "_RUL0tiGUL72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Out-of-Bag (OOB) Evaluation\n",
        "\n",
        "Out-of-Bag evaluation memungkinkan estimasi performa model tanpa validation set terpisah, dengan memanfaatkan data yang tidak terpilih selama proses bootstrap sampling.\n"
      ],
      "metadata": {
        "id": "ivThaTR8UNrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_oob = BaggingClassifier(\n",
        "    DecisionTreeClassifier(),\n",
        "    n_estimators=300,\n",
        "    bootstrap=True,\n",
        "    oob_score=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "bag_oob.fit(X_train, y_train)\n",
        "bag_oob.oob_score_\n"
      ],
      "metadata": {
        "id": "bk7uRRM5UPUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Random Forest\n",
        "\n",
        "Random Forest merupakan ensemble Decision Tree yang dilatih menggunakan Bagging dengan tambahan randomisasi fitur pada setiap split.\n"
      ],
      "metadata": {
        "id": "qHHA2UNdUQ2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_leaf_nodes=16,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "jgQlgEktUR4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Boosting\n",
        "\n",
        "Boosting melatih model secara berurutan, di mana setiap model baru berfokus memperbaiki kesalahan model sebelumnya.\n"
      ],
      "metadata": {
        "id": "f0X4PbM1UTQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1),\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "ada_clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "Ifky-DF-UUcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Closing Summary (Chapter 7)\n",
        "\n",
        "Bab ini membahas berbagai teknik Ensemble Learning, termasuk Voting, Bagging, Random Forest, Boosting, dan Stacking. Pendekatan ini menunjukkan bahwa kombinasi beberapa model yang beragam mampu menghasilkan sistem Machine Learning yang lebih kuat, stabil, dan akurat dibandingkan model tunggal.\n"
      ],
      "metadata": {
        "id": "Ni3dbHHsUVt5"
      }
    }
  ]
}