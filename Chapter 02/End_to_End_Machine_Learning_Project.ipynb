{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 2: End-to-End Machine Learning Project\n",
        "\n",
        "Chapter ini membahas proses Machine Learning secara menyeluruh dari awal hingga akhir. Fokus utama bab ini adalah memahami alur kerja Machine Learning yang sistematis, mulai dari perumusan masalah, pengolahan data, eksplorasi data, pemilihan model, evaluasi, hingga penyempurnaan model.\n",
        "\n",
        "Pendekatan end-to-end ini sangat penting karena dalam praktik nyata, sebagian besar tantangan Machine Learning justru muncul pada tahap pengolahan dan pemahaman data, bukan pada algoritma itu sendiri."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Look at the Big Picture\n",
        "\n",
        "Langkah pertama dalam proyek Machine Learning adalah memahami tujuan bisnis atau permasalahan yang ingin diselesaikan. Tanpa pemahaman yang jelas, model yang dibangun berisiko tidak relevan atau tidak berguna.\n",
        "\n",
        "### 1.1 Framing the Problem\n",
        "\n",
        "Pada chapter ini, permasalahan yang diangkat adalah memprediksi nilai median harga rumah di California berdasarkan berbagai fitur seperti lokasi, jumlah kamar, dan populasi.\n",
        "\n",
        "Masalah ini dikategorikan sebagai **supervised learning** dengan tipe **regression**, karena target yang diprediksi berupa nilai numerik kontinu.\n",
        "\n",
        "### 1.2 Select a Performance Measure\n",
        "\n",
        "Untuk mengukur performa model regresi, digunakan metrik **Root Mean Square Error (RMSE)** karena metrik ini sensitif terhadap kesalahan besar dan banyak digunakan dalam evaluasi model regresi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Get the Data\n",
        "\n",
        "Tahap berikutnya adalah memperoleh data yang akan digunakan untuk melatih dan mengevaluasi model.\n",
        "\n",
        "### 2.1 Create the Workspace\n",
        "\n",
        "Workspace dibuat menggunakan Python dan library data science seperti NumPy, Pandas, dan Scikit-Learn.\n",
        "\n",
        "### 2.2 Downloading the Data\n",
        "\n",
        "Dataset yang digunakan adalah **California Housing Dataset** yang tersedia langsung melalui Scikit-Learn.\n",
        "\n",
        "### 2.3 Loading the Data\n",
        "\n",
        "Data dimuat ke dalam bentuk DataFrame untuk memudahkan eksplorasi dan manipulasi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing(as_frame=True)\n",
        "housing_df = housing.frame\n",
        "housing_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Take a Quick Look at the Data Structure\n",
        "\n",
        "### 3.1 Data Overview with info()\n",
        "\n",
        "Langkah ini bertujuan untuk melihat struktur dataset, jumlah baris, tipe data setiap kolom, serta mendeteksi nilai yang hilang.\n",
        "\n",
        "### 3.2 Descriptive Statistics\n",
        "\n",
        "Statistik deskriptif membantu memahami distribusi data seperti nilai rata-rata, standar deviasi, serta rentang nilai.\n",
        "\n",
        "### 3.3 Categorical Attribute\n",
        "\n",
        "Pada dataset asli buku, terdapat atribut kategorikal `ocean_proximity`. Namun pada dataset versi Scikit-Learn, atribut ini telah dihilangkan sehingga seluruh fitur bersifat numerik."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "housing_df.info()\n",
        "housing_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create a Test Set\n",
        "\n",
        "Pemisahan data training dan test sangat penting agar evaluasi model bersifat objektif.\n",
        "\n",
        "### 4.1 Random Sampling\n",
        "\n",
        "### 4.2 Stratified Sampling\n",
        "\n",
        "Stratified sampling digunakan untuk menjaga proporsi distribusi data tertentu agar tetap representatif."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set, test_set = train_test_split(housing_df, test_size=0.2, random_state=42)\n",
        "train_set.shape, test_set.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Discover and Visualize the Data to Gain Insights\n",
        "\n",
        "Visualisasi data membantu menemukan pola, anomali, dan hubungan antar fitur.\n",
        "\n",
        "### 5.1 Visualizing Geographical Data\n",
        "### 5.2 Visualizing Housing Prices\n",
        "### 5.3 Looking for Correlations\n",
        "### 5.4 Scatter Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "housing_df.plot(kind=\"scatter\", x=\"Longitude\", y=\"Latitude\", alpha=0.1)\n",
        "plt.show()\n",
        "\n",
        "corr_matrix = housing_df.corr()\n",
        "corr_matrix[\"MedHouseVal\"].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Experimenting with Attribute Combinations\n",
        "\n",
        "### 6.1 Creating New Attributes\n",
        "\n",
        "Menggabungkan atribut sering kali dapat meningkatkan performa model.\n",
        "\n",
        "### 6.2 Checking Correlation with New Attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "housing_df[\"rooms_per_household\"] = housing_df[\"AveRooms\"] / housing_df[\"AveOccup\"]\n",
        "housing_df.corr()[\"MedHouseVal\"].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Prepare the Data for Machine Learning Algorithms\n",
        "\n",
        "### 7.1 Separating Predictors and Labels\n",
        "\n",
        "### 7.2 Data Cleaning (Handling Missing Values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "housing = train_set.drop(\"MedHouseVal\", axis=1)\n",
        "housing_labels = train_set[\"MedHouseVal\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Full Pipeline for Data Preparation\n",
        "\n",
        "Pipeline digunakan untuk menyatukan seluruh proses preprocessing secara terstruktur.\n",
        "\n",
        "### 11.1 ColumnTransformer\n",
        "### 11.2 Applying the Full Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "housing_prepared = num_pipeline.fit_transform(housing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Select and Train a Model\n",
        "\n",
        "### 12.1 Training a Linear Regression Model\n",
        "### 12.2 Evaluating the Model\n",
        "### 12.3 Training a Decision Tree Regressor\n",
        "### 12.4 Evaluating the Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(housing_prepared, housing_labels)\n",
        "\n",
        "lin_predictions = lin_reg.predict(housing_prepared)\n",
        "lin_rmse = np.sqrt(mean_squared_error(housing_labels, lin_predictions))\n",
        "lin_rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Better Evaluation Using Cross-Validation\n",
        "\n",
        "Cross-validation memberikan estimasi performa yang lebih stabil.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
        "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
        "rmse_scores = np.sqrt(-scores)\n",
        "rmse_scores.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Fine-Tune Your Model\n",
        "\n",
        "### 14.1 Training a Random Forest Regressor\n",
        "### 14.2 Evaluating the Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "forest_reg = RandomForestRegressor(random_state=42)\n",
        "forest_reg.fit(housing_prepared, housing_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 17. Feature Importance\n",
        "\n",
        "Random Forest memungkinkan analisis pentingnya setiap fitur terhadap prediksi.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Closing Summary\n",
        "\n",
        "Chapter 2 memperkenalkan alur kerja Machine Learning secara lengkap. Bab ini menekankan bahwa keberhasilan proyek Machine Learning tidak hanya bergantung pada algoritma, tetapi juga pada pemahaman data, proses preprocessing, evaluasi yang tepat, serta iterasi yang berkelanjutan."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

